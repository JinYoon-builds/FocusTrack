# ADR-001: 전체 이미지 분석(MobileNet)에서 좌표 기반 분석(MediaPipe)으로의 전환

* **Status:** Accepted
* **Date:** 2025-12-24

## Context (배경 및 문제점)
초기 MVP 모델(v1.0)에서는 저사양 기기 호환성을 위해 **TensorFlow MobileNet**을 사용하여 전체 이미지의 특징 벡터(Feature Vector)를 추출하고, 이를 KNN으로 분류하여 집중/딴짓 여부를 판단하려 했다.

그러나 실제 테스트 결과 다음과 같은 치명적인 문제가 발견되었다.
1.  **배경 의존성 문제:** 사용자의 행동(핸드폰 사용 등)보다 뒤에 있는 배경(Background)의 픽셀 정보가 벡터에 더 큰 영향을 미침.
2.  **오분류:** 사용자가 화면에 없거나 딴짓을 해도, 배경이 그대로면 '집중'으로 잘못 판단함. 배경을 바꾸면 결과가 달라짐.

## Decision (결정 사항)
이미지 전체의 픽셀 정보를 분석하는 **CNN(MobileNet) 방식을 폐기**하고, **MediaPipe를 활용한 좌표(Landmark) 기반 분석 방식**으로 전환한다.

1.  **Feature Extraction:** 이미지 전체가 아닌, 사람의 주요 관절 및 얼굴 랜드마크(Coordinates)만 추출한다.
2.  **Classification:** 추출된 좌표 데이터(벡터)를 기반으로 KNN 또는 간단한 분류기를 돌려 집중도를 판단한다.
3.  **Approach:** 단순 Rule-base 하드코딩이 아닌, 캘리브레이션 과정을 포함한 데이터 기반 학습 방식을 유지한다.

## Consequences (결과 및 기대 효과)
* **Positive:** 배경이 바뀌어도 사람의 행동(포즈)만 정확히 인식할 수 있다. (배경 노이즈 제거)
* **Positive:** 이미지 전체를 처리하는 것보다 연산량이 줄어들어 저사양 기기에서 더 유리하다.
* **Negative:** 랜드마크 추출을 위한 새로운 파이프라인을 처음부터 다시 개발해야 한다.